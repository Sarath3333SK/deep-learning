{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Multiclass classification using Tensorflow"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Understanding Dataset\n\nThe dataset which we will work on is 102 flower classification.\n\nThis dataset contains flowers of 102 categories, each class consisting of between 40 and 258 images. As classes were quite many so accordingly dataset was quite less which was a total of 8,189 images.\n\nThe data format is simple, a directory containing images and a .mat file containing labels.\n\n### Loading Datase\nYou can use this code to download and extract data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\n!tar -xzf 102flowers.tgz\n!rm 102flowers.tgz\n!wget http://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat","execution_count":2,"outputs":[{"output_type":"stream","text":"--2020-07-14 03:29:57--  http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\nResolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\nConnecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 344862509 (329M) [application/x-gzip]\nSaving to: ‘102flowers.tgz’\n\n102flowers.tgz      100%[===================>] 328.89M  11.7MB/s    in 30s     \n\n2020-07-14 03:30:28 (10.9 MB/s) - ‘102flowers.tgz’ saved [344862509/344862509]\n\n--2020-07-14 03:30:34--  http://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat\nResolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\nConnecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 502\nSaving to: ‘imagelabels.mat’\n\nimagelabels.mat     100%[===================>]     502  --.-KB/s    in 0s      \n\n2020-07-14 03:30:35 (74.4 MB/s) - ‘imagelabels.mat’ saved [502/502]\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"As always we will start with importing needed libraries:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport scipy.io\nimport cv2\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pre-Processing\n\nLoading labels:"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_labels = scipy.io.loadmat(\"imagelabels.mat\")\nimg_labels = img_labels[\"labels\"]\nimg_labels = img_labels[0]\nfor i in range(len(img_labels)):\n  img_labels[i] = img_labels[i] - 1","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading images and converting them to NumPy array:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = []\ntrain_y = []\ndir = \"jpg/\"\nfor imgs in os.listdir(dir):\n  img_num = int(imgs[7:11])-1\n  train_y.append(img_labels[img_num])\n  image = cv2.imread(os.path.join(dir, imgs))\n  resized = cv2.resize(image, (150,150))\n  normalized_img = cv2.normalize(resized, None, alpha=0, beta=1, \n                            norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n  train_x.append(normalized_img)\ntrain_x = np.array(train_x)","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting data in training and testing sets:"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainx, valx, trainy, valy = train_test_split(train_x, train_y, test_size=0.15, random_state=10)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training Dataset Shape: ­{}'.format(trainx.shape))\nprint('No. of Training Dataset Labels: {}'.format(len(trainy)))","execution_count":7,"outputs":[{"output_type":"stream","text":"Training Dataset Shape: ­(6960, 150, 150, 3)\nNo. of Training Dataset Labels: 6960\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Reshaping and exploring data again:"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_images= trainx/255.0\ntest_images=valx/255.0\n\ntraining_images = trainx.reshape((6960,150,150,3))\nvalx = valx.reshape((1229,150,150,3))\nprint('Training Dataset Shape: ­{}'.format(trainx.shape))\nprint('No. of Training Dataset Labels: {}'.format(len(trainy)))\nprint('Test Dataset Shape: {}'.format(valx.shape))\nprint('No. of Test Dataset Labels: {}'.format(len(valy)))","execution_count":8,"outputs":[{"output_type":"stream","text":"Training Dataset Shape: ­(6960, 150, 150, 3)\nNo. of Training Dataset Labels: 6960\nTest Dataset Shape: (1229, 150, 150, 3)\nNo. of Test Dataset Labels: 1229\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Converting to categorical:"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainy = to_categorical(trainy)\nvaly = to_categorical(valy)","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# fn to create weights\ndef create_weights(shape):\n    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n # fn to create biases\ndef create_biases(size):\n    return tf.Variable(tf.constant(0.05, shape=[size]))\n\n# fn to create convolutional layer\ndef create_convolutional_layer(input,num_input_channels, conv_filter_size, num_filters):  \n    weights = create_weights(shape=[conv_filter_size, conv_filter_size, num_input_channels, num_filters])\n    biases = create_biases(num_filters)\n \n    layer = tf.nn.conv2d(input=input, filter=weights,strides=[1, 1, 1, 1],padding='SAME')\n    layer += biases\n    layer = tf.nn.relu(layer)  \n    layer = tf.nn.max_pool(value=layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n    \n    return layer\n\n# fn to create flatten layer\ndef create_flatten_layer(layer):\n    layer_shape = layer.get_shape()\n    num_features = layer_shape[1:4].num_elements()\n    layer = tf.reshape(layer, [-1, num_features])\n \n    return layer\n \n # fn to create fully connected layers\ndef create_fc_layer(input, num_inputs, num_outputs, use_relu=True):\n    weights = create_weights(shape=[num_inputs, num_outputs])\n    biases = create_biases(num_outputs)\n    \n    if use_relu:\n        layer = tf.add(tf.matmul(input, weights), biases)\n        layer = tf.nn.relu(layer)\n    else:\n        layer = tf.add(tf.matmul(input, weights), biases, name='y_preds')\n\n    return layer","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then initializing constants which will be used further like Batch size and Epochs."},{"metadata":{"trusted":true},"cell_type":"code","source":"## INITIALIZING CONSTANTS\nx = tf.placeholder(tf.float32, shape=[None, 150,150,3], name='x')\ny = tf.placeholder(tf.float32, shape=[None, 102], name='y')\nNUM_EPOCHS = 2\nBATCH_SIZE = 500\nKEEP_PROB = 0.5","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## BUILDING CNN\n\n# Adding 1st convolutional layer\n\nblock1_conv1 = create_convolutional_layer(input=x, num_input_channels=3, conv_filter_size=3, num_filters=64)\nblock1_conv2 = create_convolutional_layer(input=block1_conv1, num_input_channels=64,conv_filter_size=3, num_filters=128) \nbatch1 = tf.layers.batch_normalization(block1_conv2) \ndrop1 = tf.nn.dropout(batch1, KEEP_PROB)\n\n# Adding 2nd convolutional layer\nblock2_conv1 = create_convolutional_layer(input=drop1, num_input_channels=128, conv_filter_size=3, num_filters=128)\nblock2_conv2 = create_convolutional_layer(input=block2_conv1, num_input_channels=128, conv_filter_size=3, num_filters=256)\nbatch2 = tf.layers.batch_normalization(block2_conv2) \ndrop2 = tf.nn.dropout(batch2, KEEP_PROB)\n\n# Adding 3rd convolutional layer\nblock3_conv1 = create_convolutional_layer(input=drop2, num_input_channels=256, conv_filter_size=3, num_filters=256)\nblock3_conv2 = create_convolutional_layer(input=block3_conv1, num_input_channels=256, conv_filter_size=3, num_filters=512)\nbatch3 = tf.layers.batch_normalization(block3_conv2) \ndrop3 = tf.nn.dropout(batch3, KEEP_PROB)\nlayer_flat = create_flatten_layer(drop3)\n\nlayer_fc1 = create_fc_layer(input=layer_flat, num_inputs=layer_flat.get_shape()[1:4].num_elements(), num_outputs=1024, use_relu=True)\nbatch5 = tf.layers.batch_normalization(layer_fc1)\ndrop5 = tf.nn.dropout(batch5, KEEP_PROB)\n\n#output layer\ny_preds = create_fc_layer(input=drop5, num_inputs=1024, num_outputs=102, use_relu=False)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## CALCULATING COST AND ACCURACY\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_preds, labels=y))\noptimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\ncorrect_pred = tf.equal(tf.argmax(y_preds, 1), tf.argmax(y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training and saving model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"init = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    for epoch in range(NUM_EPOCHS):\n      for batch in range(int(len(trainx)/BATCH_SIZE)):\n        batch_x = trainx[batch*BATCH_SIZE:min((batch+1)*BATCH_SIZE,len(trainx))]\n        batch_y = trainy[batch*BATCH_SIZE:min((batch+1)*BATCH_SIZE,len(trainy))]\n\n        opt = sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n        loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x, y: batch_y})\n\n      for batch in range(int(len(valx)/BATCH_SIZE)):\n        val_batch_x = valx[batch*BATCH_SIZE:min((batch+1)*BATCH_SIZE,len(valx))]\n        val_batch_y = valy[batch*BATCH_SIZE:min((batch+1)*BATCH_SIZE,len(valy))]\n\n        val_loss, val_acc= sess.run([cost, accuracy], feed_dict={x: val_batch_x, y: val_batch_y})\n        \n      print(\"Epoch \"+str(epoch+1)+\": Train Loss= \"+\"{:.4f}\".format(loss)+\"   Train Accuracy= \" +  \"{:.4f}\".format(acc)+\n              \"   Valid Loss= \"+\"{:.4f}\".format(val_loss)+\"   Valid Accuracy= \" + \"{:.4f}\".format(val_acc))\n\n    ## SAVING THE MODEL\n    os.mkdir('/model5')\n    tf.saved_model.simple_save(sess, '/model5', inputs={\"x\": x}, outputs={\"y_preds\": y_preds})\n    print('--- MODEL SAVED ---')","execution_count":14,"outputs":[{"output_type":"stream","text":"Epoch 1: Train Loss= 4.5926   Train Accuracy= 0.0260   Valid Loss= 4.5563   Valid Accuracy= 0.0300\nEpoch 2: Train Loss= 4.5511   Train Accuracy= 0.0360   Valid Loss= 4.5162   Valid Accuracy= 0.0320\n--- MODEL SAVED ---\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Inferencing the saved model"},{"metadata":{"trusted":true},"cell_type":"code","source":"graph = tf.Graph()\nwith graph.as_default():\n    with tf.Session(graph=graph) as sess:\n        tf.saved_model.loader.load(sess, [\"serve\"], '/model5')\n\n        x = graph.get_tensor_by_name('x:0')\n        y_preds = graph.get_tensor_by_name('y_preds:0')\n        \n        y_true = []\n        preds = []\n        for batch in range(int(len(valx)/BATCH_SIZE)):\n          batch_x = valx[batch*BATCH_SIZE:min((batch+1)*BATCH_SIZE,len(valx))]\n          batch_y = valy[batch*BATCH_SIZE:min((batch+1)*BATCH_SIZE,len(valy))]\n\n          y_true.append(batch_y)\n          preds.append(sess.run(y_preds, feed_dict={x: batch_x}))\n\n        y_true = np.stack(np.array(y_true), axis=0)\n        preds = np.stack(np.array(preds), axis=0)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = tf.cast(preds, tf.float32), \n                                                              labels=tf.cast(y_true, tf.float32)))\ncorrect = tf.equal(np.argmax(preds, axis=2), np.argmax(y_true, axis=2))\naccuracy = tf.reduce_mean(tf.cast(correct, tf.float32))","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.Session() as sess:\n    print('Loss :',loss.eval())\n    print('Accuracy :', accuracy.eval())","execution_count":17,"outputs":[{"output_type":"stream","text":"Loss : 4.5263968\nAccuracy : 0.035\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### Accuracy is very low because of less training epoches because I wrote this code to show just the impletation part, Increase them to get better results."},{"metadata":{},"cell_type":"markdown","source":"## Future Implementation\nAs this is just a basic model for learning phase, these things can be further done to improve effeciency:\n\n* As dataset was small, so need of data augumentation.\n* Finding more architectures to improve the accuracy."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}